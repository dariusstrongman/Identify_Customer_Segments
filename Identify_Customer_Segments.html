<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>4421e35d6df84e8388294b11bae38077</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="project-identify-customer-segments" class="cell markdown">
<h1>Project: Identify Customer Segments</h1>
<p>In this project, you will apply unsupervised learning techniques to
identify segments of the population that form the core customer base for
a mail-order sales company in Germany. These segments can then be used
to direct marketing campaigns towards audiences that will have the
highest expected rate of returns. The data that you will use has been
provided by our partners at Bertelsmann Arvato Analytics, and represents
a real-life data science task.</p>
<p>This notebook will help you complete this task by providing a
framework within which you will perform your analysis steps. In each
step of the project, you will see some text describing the subtask that
you will perform, followed by one or more code cells for you to complete
your work. <strong>Feel free to add additional code and markdown cells
as you go along so that you can explore everything in precise
chunks.</strong> The code cells provided in the base template will
outline only the major tasks, and will usually not be enough to cover
all of the minor tasks that comprise it.</p>
<p>It should be noted that while there will be precise guidelines on how
you should handle certain tasks in the project, there will also be
places where an exact specification is not provided. <strong>There will
be times in the project where you will need to make and justify your own
decisions on how to treat the data.</strong> These are places where
there may not be only one way to handle the data. In real-life tasks,
there may be many valid ways to approach an analysis task. One of the
most important things you can do is clearly document your approach so
that other scientists can understand the decisions you've made.</p>
<p>At the end of most sections, there will be a Markdown cell labeled
<strong>Discussion</strong>. In these cells, you will report your
findings for the completed section, as well as document the decisions
that you made in your approach to each subtask. <strong>Your project
will be evaluated not just on the code used to complete the tasks
outlined, but also your communication about your observations and
conclusions at each stage.</strong></p>
</section>
<div class="cell code" data-execution_count="1">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import libraries here; add more as necessary</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># magic word for producing visualizations in notebook</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">Import note: The classroom currently uses sklearn version 0.19.</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">If you need to use an imputer, it is available in sklearn.preprocessing.Imputer,</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">instead of sklearn.impute as in newer versions of sklearn.</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="1">
<pre><code>&#39;\nImport note: The classroom currently uses sklearn version 0.19.\nIf you need to use an imputer, it is available in sklearn.preprocessing.Imputer,\ninstead of sklearn.impute as in newer versions of sklearn.\n&#39;</code></pre>
</div>
</div>
<section id="step-0-load-the-data" class="cell markdown">
<h3>Step 0: Load the Data</h3>
<p>There are four files associated with this project (not including this
one):</p>
<ul>
<li><code>Udacity_AZDIAS_Subset.csv</code>: Demographics data for the
general population of Germany; 891211 persons (rows) x 85 features
(columns).</li>
<li><code>Udacity_CUSTOMERS_Subset.csv</code>: Demographics data for
customers of a mail-order company; 191652 persons (rows) x 85 features
(columns).</li>
<li><code>Data_Dictionary.md</code>: Detailed information file about the
features in the provided datasets.</li>
<li><code>AZDIAS_Feature_Summary.csv</code>: Summary of feature
attributes for demographics data; 85 features (rows) x 4 columns</li>
</ul>
<p>Each row of the demographics files represents a single person, but
also includes information outside of individuals, including information
about their household, building, and neighborhood. You will use this
information to cluster the general population into groups with similar
demographic properties. Then, you will see how the people in the
customers dataset fit into those created clusters. The hope here is that
certain clusters are over-represented in the customers data, as compared
to the general population; those over-represented clusters will be
assumed to be part of the core userbase. This information can then be
used for further applications, such as targeting for a marketing
campaign.</p>
<p>To start off with, load in the demographics data for the general
population into a pandas DataFrame, and do the same for the feature
attributes summary. Note for all of the <code>.csv</code> data files in
this project: they're semicolon (<code>;</code>) delimited, so you'll
need an additional argument in your <a
href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"><code>read_csv()</code></a>
call to read in the data properly. Also, considering the size of the
main dataset, it may take some time for it to load completely.</p>
<p>Once the dataset is loaded, it's recommended that you take a little
bit of time just browsing the general structure of the dataset and
feature summary file. You'll be getting deep into the innards of the
cleaning in the first major step of the project, so gaining some general
familiarity can help you get your bearings.</p>
</section>
<div class="cell code" data-execution_count="2">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load in the general demographics data.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>azdias <span class="op">=</span> pd.read_csv(<span class="st">&#39;Udacity_AZDIAS_Subset.csv&#39;</span>, sep<span class="op">=</span><span class="st">&#39;;&#39;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load in the feature summary file.</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>feat_info <span class="op">=</span> pd.read_csv(<span class="st">&#39;AZDIAS_Feature_Summary.csv&#39;</span>, sep<span class="op">=</span><span class="st">&#39;;&#39;</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;ok&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>ok
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="3">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the structure of the data after it&#39;s loaded (e.g. print the number of</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># rows and columns, print the first few rows).</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(azdias.shape, feat_info.shape)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking azdias</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>azdias.head(<span class="dv">10</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>(891221, 85) (85, 4)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="3">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AGER_TYP</th>
      <th>ALTERSKATEGORIE_GROB</th>
      <th>ANREDE_KZ</th>
      <th>CJT_GESAMTTYP</th>
      <th>FINANZ_MINIMALIST</th>
      <th>FINANZ_SPARER</th>
      <th>FINANZ_VORSORGER</th>
      <th>FINANZ_ANLEGER</th>
      <th>FINANZ_UNAUFFAELLIGER</th>
      <th>FINANZ_HAUSBAUER</th>
      <th>...</th>
      <th>PLZ8_ANTG1</th>
      <th>PLZ8_ANTG2</th>
      <th>PLZ8_ANTG3</th>
      <th>PLZ8_ANTG4</th>
      <th>PLZ8_BAUMAX</th>
      <th>PLZ8_HHZ</th>
      <th>PLZ8_GBZ</th>
      <th>ARBEIT</th>
      <th>ORTSGR_KLS9</th>
      <th>RELAT_AB</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1</td>
      <td>2</td>
      <td>1</td>
      <td>2.0</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>5</td>
      <td>5</td>
      <td>3</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1</td>
      <td>1</td>
      <td>2</td>
      <td>5.0</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
      <td>5</td>
      <td>4</td>
      <td>5</td>
      <td>...</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1</td>
      <td>3</td>
      <td>2</td>
      <td>3.0</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>5</td>
      <td>...</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>2.0</td>
      <td>4</td>
      <td>2</td>
      <td>5</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1</td>
      <td>3</td>
      <td>1</td>
      <td>5.0</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>2</td>
      <td>...</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>2.0</td>
      <td>3</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
      <td>2</td>
      <td>5</td>
      <td>...</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-1</td>
      <td>2</td>
      <td>2</td>
      <td>5.0</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>5</td>
      <td>4</td>
      <td>3</td>
      <td>...</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-1</td>
      <td>1</td>
      <td>1</td>
      <td>3.0</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>2</td>
      <td>...</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-1</td>
      <td>3</td>
      <td>1</td>
      <td>3.0</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-1</td>
      <td>3</td>
      <td>2</td>
      <td>4.0</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
      <td>5</td>
      <td>4</td>
      <td>...</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 85 columns</p>
</div>
</div>
</div>
<div class="cell code" data-execution_count="4">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking feat_info</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>feat_info.head(<span class="dv">10</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>attribute</th>
      <th>information_level</th>
      <th>type</th>
      <th>missing_or_unknown</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AGER_TYP</td>
      <td>person</td>
      <td>categorical</td>
      <td>[-1,0]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ALTERSKATEGORIE_GROB</td>
      <td>person</td>
      <td>ordinal</td>
      <td>[-1,0,9]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ANREDE_KZ</td>
      <td>person</td>
      <td>categorical</td>
      <td>[-1,0]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CJT_GESAMTTYP</td>
      <td>person</td>
      <td>categorical</td>
      <td>[0]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>FINANZ_MINIMALIST</td>
      <td>person</td>
      <td>ordinal</td>
      <td>[-1]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>FINANZ_SPARER</td>
      <td>person</td>
      <td>ordinal</td>
      <td>[-1]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>FINANZ_VORSORGER</td>
      <td>person</td>
      <td>ordinal</td>
      <td>[-1]</td>
    </tr>
    <tr>
      <th>7</th>
      <td>FINANZ_ANLEGER</td>
      <td>person</td>
      <td>ordinal</td>
      <td>[-1]</td>
    </tr>
    <tr>
      <th>8</th>
      <td>FINANZ_UNAUFFAELLIGER</td>
      <td>person</td>
      <td>ordinal</td>
      <td>[-1]</td>
    </tr>
    <tr>
      <th>9</th>
      <td>FINANZ_HAUSBAUER</td>
      <td>person</td>
      <td>ordinal</td>
      <td>[-1]</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<blockquote>
<p><strong>Tip</strong>: Add additional cells to keep everything in
reasonably-sized chunks! Keyboard shortcut <code>esc --&gt; a</code>
(press escape to enter command mode, then press the 'A' key) adds a new
cell before the active cell, and <code>esc --&gt; b</code> adds a new
cell after the active cell. If you need to convert an active cell to a
markdown cell, use <code>esc --&gt; m</code> and to convert to a code
cell, use <code>esc --&gt; y</code>.</p>
</blockquote>
<h2 id="step-1-preprocessing">Step 1: Preprocessing</h2>
<h3 id="step-11-assess-missing-data">Step 1.1: Assess Missing Data</h3>
<p>The feature summary file contains a summary of properties for each
demographics data column. You will use this file to help you make
cleaning decisions during this stage of the project. First of all, you
should assess the demographics data in terms of missing data. Pay
attention to the following points as you perform your analysis, and take
notes on what you observe. Make sure that you fill in the
<strong>Discussion</strong> cell with your findings and decisions at the
end of each step that has one!</p>
<h4 id="step-111-convert-missing-value-codes-to-nans">Step 1.1.1:
Convert Missing Value Codes to NaNs</h4>
<p>The fourth column of the feature attributes summary (loaded in above
as <code>feat_info</code>) documents the codes from the data dictionary
that indicate missing or unknown data. While the file encodes this as a
list (e.g. <code>[-1,0]</code>), this will get read in as a string
object. You'll need to do a little bit of parsing to make use of it to
identify and clean the data. Convert data that matches a 'missing' or
'unknown' value code into a numpy NaN value. You might want to see how
much data takes on a 'missing' or 'unknown' code, and how much data is
naturally missing, as a point of interest.</p>
<p><strong>As one more reminder, you are encouraged to add additional
cells to break up your analysis into manageable chunks.</strong></p>
</div>
<div class="cell code" data-execution_count="5">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify missing or unknown data values and convert them to NaNs.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ast <span class="im">import</span> literal_eval <span class="im">as</span> lit</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_nan(df, feat_info, verbose<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    iterable_obj <span class="op">=</span> tqdm(feat_info.index) <span class="cf">if</span> verbose <span class="cf">else</span> feat_info.index</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> iterable_obj:</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        feature <span class="op">=</span> feat_info.loc[i, <span class="st">&#39;attribute&#39;</span>]</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        missing_codes_str <span class="op">=</span> feat_info.loc[i, <span class="st">&#39;missing_or_unknown&#39;</span>]</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        missing_codes_str <span class="op">=</span> missing_codes_str.replace(<span class="st">&quot;,X&quot;</span>, <span class="st">&quot;,&#39;X&quot;</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        missing_codes_str <span class="op">=</span> missing_codes_str.replace(<span class="st">&quot;X]&quot;</span>, <span class="st">&quot;X&#39;]&quot;</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        missing_codes_str <span class="op">=</span> missing_codes_str.replace(<span class="st">&quot;[X&quot;</span>, <span class="st">&quot;[&#39;X&quot;</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        missing_codes <span class="op">=</span> lit(missing_codes_str)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        df_copy[feature] <span class="op">=</span> df_copy[feature].<span class="bu">apply</span>(<span class="kw">lambda</span> x: np.nan <span class="cf">if</span> x <span class="kw">in</span> missing_codes <span class="cf">else</span> x)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>azdias_with_missing <span class="op">=</span> to_nan(azdias, feat_info)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>100%|██████████| 85/85 [01:04&lt;00:00,  1.41it/s]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Missing data detected, before and after.</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nan_info(df, disp<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    n_rows, n_cols <span class="op">=</span> df.shape</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    n_values <span class="op">=</span> n_rows <span class="op">*</span> n_cols</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    nan_values <span class="op">=</span> df.isnull().<span class="bu">sum</span>().<span class="bu">sum</span>()</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    nan_rows <span class="op">=</span> n_rows <span class="op">-</span> df.dropna().shape[<span class="dv">0</span>]</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> disp:</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;There are </span><span class="sc">{</span>nan_values<span class="sc">}</span><span class="ss"> missing values. (</span><span class="sc">{</span>nan_values<span class="op">/</span>n_values<span class="op">*</span><span class="dv">100</span><span class="sc">:.4}</span><span class="ss">%).&#39;</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;There are </span><span class="sc">{</span>nan_rows<span class="sc">}</span><span class="ss"> rows with missing values. (</span><span class="sc">{</span>nan_rows<span class="op">/</span>n_rows<span class="op">*</span><span class="dv">100</span><span class="sc">:.4}</span><span class="ss">%).&#39;</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> n_values, nan_values, n_rows, nan_rows</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Before Parsing:&#39;</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>nan_info(azdias)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">After Parsing:&#39;</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>nan_info(azdias_with_missing)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Before Parsing:
There are 4896838 missing values. (6.464%).
There are 628074 rows with missing values. (70.47%).

After Parsing:
There are 8373929 missing values. (11.05%).
There are 891078 rows with missing values. (99.98%).
</code></pre>
</div>
</div>
<section id="step-112-assess-missing-data-in-each-column"
class="cell markdown">
<h4>Step 1.1.2: Assess Missing Data in Each Column</h4>
<p>How much missing data is present in each column? There are a few
columns that are outliers in terms of the proportion of values that are
missing. You will want to use matplotlib's <a
href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html"><code>hist()</code></a>
function to visualize the distribution of missing value counts to find
these columns. Identify and document these columns. While some of these
columns might have justifications for keeping or re-encoding the data,
for this project you should just remove them from the dataframe. (Feel
free to make remarks about these outlier columns in the discussion,
however!)</p>
<p>For the remaining features, are there any patterns in which columns
have, or share, missing data?</p>
</section>
<div class="cell code" data-execution_count="7">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform an assessment of how much missing data there is in each column of the</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset.</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_missing(df):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    plt.rcParams[<span class="st">&quot;figure.figsize&quot;</span>] <span class="op">=</span> (<span class="dv">20</span>,<span class="dv">7</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    bar_x <span class="op">=</span> <span class="bu">list</span>(df.columns)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    bar_y <span class="op">=</span> [df[col].isna().<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(df) <span class="cf">for</span> col <span class="kw">in</span> bar_x]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    plt.bar(bar_x, bar_y)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;Missing values per column&#39;</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>show_missing(azdias_with_missing)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/4d39c56e3d167fc51644ee836fac14d620a61e45.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigate patterns in the amount of missing data in each column.</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>missing_proportions <span class="op">=</span> {col: azdias_with_missing[col].isna().<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(azdias_with_missing)<span class="op">\</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                       <span class="cf">for</span> col <span class="kw">in</span> azdias_with_missing.columns}</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>missing_proportions_desc <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> <span class="bu">sorted</span>(missing_proportions.items(), key<span class="op">=</span> <span class="kw">lambda</span> x: <span class="op">-</span>x[<span class="dv">1</span>])}</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>missing_proportions_asc <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> <span class="bu">sorted</span>(missing_proportions.items(), key<span class="op">=</span> <span class="kw">lambda</span> x: x[<span class="dv">1</span>])}</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>n_printed <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Most Missing:&#39;</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(missing_proportions_desc):</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">==</span> n_printed:</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{:&gt;25}{:&gt;25}</span><span class="st">&#39;</span>.<span class="bu">format</span>(col, missing_proportions_desc[col]))</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Most Reliable:&#39;</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(missing_proportions_asc):</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">==</span> n_printed:</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{:&gt;25}{:&gt;25}</span><span class="st">&#39;</span>.<span class="bu">format</span>(col, missing_proportions_asc[col]))</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Most Missing:
                 TITEL_KZ       0.9975763587258379
                 AGER_TYP       0.7695543529607134
             KK_KUNDENTYP       0.6559674873011295
             KBA05_BAUMAX       0.5346866826522265
              GEBURTSJAHR       0.4402028228688507
                 ALTER_HH      0.34813699407890975
                      KKK      0.17735668257368262
                 REGIOTYP      0.17735668257368262
           W_KEIT_KIND_HH      0.16605084485217472
              KBA05_ANTG1      0.14959701353536328
              KBA05_ANTG2      0.14959701353536328
              KBA05_ANTG3      0.14959701353536328
              KBA05_ANTG4      0.14959701353536328
                KBA05_GBZ      0.14959701353536328
               MOBI_REGIO      0.14959701353536328
               PLZ8_ANTG1      0.13073637178657146
               PLZ8_ANTG2      0.13073637178657146
               PLZ8_ANTG3      0.13073637178657146
               PLZ8_ANTG4      0.13073637178657146
              PLZ8_BAUMAX      0.13073637178657146
                 PLZ8_HHZ      0.13073637178657146
                 PLZ8_GBZ      0.13073637178657146
               HEALTH_TYP      0.12476815514894735
              SHOPPER_TYP      0.12476815514894735
                 VERS_TYP      0.12476815514894735

Most Reliable:
                ANREDE_KZ                      0.0
        FINANZ_MINIMALIST                      0.0
            FINANZ_SPARER                      0.0
         FINANZ_VORSORGER                      0.0
           FINANZ_ANLEGER                      0.0
    FINANZ_UNAUFFAELLIGER                      0.0
         FINANZ_HAUSBAUER                      0.0
                FINANZTYP                      0.0
         GREEN_AVANTGARDE                      0.0
                SEMIO_SOZ                      0.0
                SEMIO_FAM                      0.0
                SEMIO_REL                      0.0
                SEMIO_MAT                      0.0
               SEMIO_VERT                      0.0
               SEMIO_LUST                      0.0
                SEMIO_ERL                      0.0
               SEMIO_KULT                      0.0
                SEMIO_RAT                      0.0
               SEMIO_KRIT                      0.0
                SEMIO_DOM                      0.0
               SEMIO_KAEM                      0.0
            SEMIO_PFLICHT                      0.0
              SEMIO_TRADV                      0.0
                 ZABEOTYP                      0.0
     ALTERSKATEGORIE_GROB    0.0032326437550282143
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="9">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Collecting reliable columns</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>reliable_cols <span class="op">=</span> {col: missing_proportions[col] <span class="cf">for</span> col <span class="kw">in</span> missing_proportions <span class="cf">if</span> missing_proportions[col] <span class="op">&lt;=</span> <span class="fl">0.001</span>}</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;There are </span><span class="sc">{</span><span class="bu">len</span>(reliable_cols)<span class="sc">}</span><span class="ss"> reliable columns with zero or very few missing data.&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>There are 24 reliable columns with zero or very few missing data.
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="10">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the outlier columns from the dataset. (You&#39;ll perform other data</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># engineering tasks such as re-encoding and imputation later.)</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_outlier_cols(df, outliers):</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df.drop(outliers, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> missing_proportions <span class="cf">if</span> missing_proportions[col] <span class="op">&gt;</span> <span class="fl">0.3</span>]</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outliers)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>azdias_without_outliers <span class="op">=</span> remove_outlier_cols(azdias_with_missing, outliers)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>azdias_without_outliers.shape</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[&#39;AGER_TYP&#39;, &#39;GEBURTSJAHR&#39;, &#39;TITEL_KZ&#39;, &#39;ALTER_HH&#39;, &#39;KK_KUNDENTYP&#39;, &#39;KBA05_BAUMAX&#39;]
</code></pre>
</div>
<div class="output execute_result" data-execution_count="10">
<pre><code>(891221, 79)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="11">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show missing data ratio after removing outliers, now no bars are too high!</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>show_missing(azdias_without_outliers)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/882f8cc113cdeb24071ee5d49a8e1882d58c6e9d.png" /></p>
</div>
</div>
<section id="discussion-112-assess-missing-data-in-each-column"
class="cell markdown">
<h4>Discussion 1.1.2: Assess Missing Data in Each Column</h4>
<p><em>(Double click this cell and replace this text with your own text,
reporting your observations regarding the amount of missing data in each
column. Are there any patterns in missing values? Which columns were
removed from the dataset?)</em></p>
<p><strong>ANSWER:</strong> There're 24 strongly reliable columns with
zero or very rare missing values. On the other hand there're six columns
that could be considered as outliers since they've more than 30% missing
data. Those six outliers are: <em>AGER_TYP</em>, <em>GEBURTSJAHR</em>,
<em>TITEL_KZ</em>, <em>ALTER_HH</em>, <em>KK_KUNDENTYP</em> and
<em>KBA05_BAUMAX</em>. Those outliers have been dropped.</p>
</section>
<section id="step-113-assess-missing-data-in-each-row"
class="cell markdown">
<h4>Step 1.1.3: Assess Missing Data in Each Row</h4>
<p>Now, you'll perform a similar assessment for the rows of the dataset.
How much data is missing in each row? As with the columns, you should
see some groups of points that have a very different numbers of missing
values. Divide the data into two subsets: one for data points that are
above some threshold for missing values, and a second subset for points
below that threshold.</p>
<p>In order to know what to do with the outlier rows, we should see if
the distribution of data values on columns that are not missing data (or
are missing very little data) are similar or different between the two
groups. Select at least five of these columns and compare the
distribution of values.</p>
<ul>
<li>You can use seaborn's <a
href="https://seaborn.pydata.org/generated/seaborn.countplot.html"><code>countplot()</code></a>
function to create a bar chart of code frequencies and matplotlib's <a
href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html"><code>subplot()</code></a>
function to put bar charts for the two subplots side by side.</li>
<li>To reduce repeated code, you might want to write a function that can
perform this comparison, taking as one of its arguments a column to be
compared.</li>
</ul>
<p>Depending on what you observe in your comparison, this will have
implications on how you approach your conclusions later in the analysis.
If the distributions of non-missing features look similar between the
data with many missing values and the data with few or no missing
values, then we could argue that simply dropping those points from the
analysis won't present a major issue. On the other hand, if the data
with many missing values looks very different from the data with few or
no missing values, then we should make a note on those data as special.
We'll revisit these data later on. <strong>Either way, you should
continue your analysis for now using just the subset of the data with
few or no missing values.</strong></p>
</section>
<div class="cell code" data-execution_count="12">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How much data is missing in each row of the dataset?</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>missing_per_row <span class="op">=</span> azdias_without_outliers.isnull().<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>sns.countplot(missing_per_row, palette<span class="op">=</span><span class="st">&#39;Set1&#39;</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Number of rows detected having specific number of missing values.&#39;</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Number of missing values&#39;</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/9d11b3e524c7d5bd549b4686a8cce25e9ee47de9.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="13">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write code to divide the data into two subsets based on the number of missing</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># values in each row.</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split_messy_rows(df, threshold):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    df_clean <span class="op">=</span> df[df.isnull().<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">&lt;</span> threshold]</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    df_messy <span class="op">=</span> df[df.isnull().<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">&gt;=</span> threshold]</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_clean, df_messy</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>azdias_clean, azdias_messy <span class="op">=</span> split_messy_rows(azdias_without_outliers, threshold)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(azdias_clean) <span class="op">+</span> <span class="bu">len</span>(azdias_messy) <span class="op">==</span> <span class="bu">len</span>(azdias_without_outliers):</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;We are good.&#39;</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;There are </span><span class="sc">{</span><span class="bu">len</span>(azdias_clean)<span class="sc">}</span><span class="ss"> rows under threshold, and </span><span class="sc">{</span><span class="bu">len</span>(azdias_messy)<span class="sc">}</span><span class="ss"> above or equal threshold.&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>We are good.
There are 797077 rows under threshold, and 94144 above or equal threshold.
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="14">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the distribution of values for at least five columns where there are</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># no or few missing values, between the two subsets.</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_distributions(df_clean, df_messy, reliable_columns):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    plt.rcParams[<span class="st">&quot;figure.figsize&quot;</span>] <span class="op">=</span> (<span class="dv">20</span>,<span class="dv">30</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(reliable_columns)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    plt.subplots(n, <span class="dv">2</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(reliable_columns):</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        plt.subplot(n, <span class="dv">2</span>, <span class="dv">2</span><span class="op">*</span>i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        sns.countplot(data<span class="op">=</span>df_clean, x<span class="op">=</span>col)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        plt.subplot(n, <span class="dv">2</span>, <span class="dv">2</span><span class="op">*</span>i <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        sns.countplot(data<span class="op">=</span>df_messy, x<span class="op">=</span>col)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>reliable_columns <span class="op">=</span> <span class="bu">list</span>(reliable_cols) <span class="co"># Because reliable_cols is a dictionary</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>compare_distributions(azdias_clean, azdias_messy, reliable_columns[:<span class="dv">6</span>])</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/428e82fe8280c1b7d950887c8eafccdb72aaa08b.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="15">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Showing other six!</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>compare_distributions(azdias_clean, azdias_messy, reliable_columns[<span class="dv">18</span>:<span class="dv">24</span>])</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/ac7b370363c130f78696488db9e3ebb6342a62b2.png" /></p>
</div>
</div>
<section id="discussion-113-assess-missing-data-in-each-row"
class="cell markdown">
<h4>Discussion 1.1.3: Assess Missing Data in Each Row</h4>
<p><em>(Double-click this cell and replace this text with your own text,
reporting your observations regarding missing data in rows. Are the data
with lots of missing values are qualitatively different from data with
few or no missing values?)</em></p>
<p><strong>ANSWER:</strong> First, we can see in the graph of "Number of
rows detected having spacific number of missing values" that there're
almost no rows with ~20:30 missed values, rows either have far more or
far less missed values, that hints that there're actually different
distributons.</p>
<p>The graphs above largely certains that. Data with lots of missing
values are indeed qualitatively different from data with few or no
missing values. While <em>ARNEDE_KZ</em> is the only feature that has
quite similar distributions, all of the other features massively differ.
For example, <em>SEMIO PFLICHT</em> feature has 7 different values in
clean data, while has almost only 2 values in the messy data.</p>
</section>
<section id="step-12-select-and-re-encode-features"
class="cell markdown">
<h3>Step 1.2: Select and Re-Encode Features</h3>
<p>Checking for missing data isn't the only way in which you can prepare
a dataset for analysis. Since the unsupervised learning techniques to be
used will only work on data that is encoded numerically, you need to
make a few encoding changes or additional assumptions to be able to make
progress. In addition, while almost all of the values in the dataset are
encoded using numbers, not all of them represent numeric values. Check
the third column of the feature summary (<code>feat_info</code>) for a
summary of types of measurement.</p>
<ul>
<li>For numeric and interval data, these features can be kept without
changes.</li>
<li>Most of the variables in the dataset are ordinal in nature. While
ordinal values may technically be non-linear in spacing, make the
simplifying assumption that the ordinal variables can be treated as
being interval in nature (that is, kept without any changes).</li>
<li>Special handling may be necessary for the remaining two variable
types: categorical, and 'mixed'.</li>
</ul>
<p>In the first two parts of this sub-step, you will perform an
investigation of the categorical and mixed-type features and make a
decision on each of them, whether you will keep, drop, or re-encode
each. Then, in the last part, you will create a new data frame with only
the selected and engineered columns.</p>
<p>Data wrangling is often the trickiest part of the data analysis
process, and there's a lot of it to be done here. But stick with it:
once you're done with this step, you'll be ready to get to the machine
learning parts of the project!</p>
</section>
<div class="cell code" data-execution_count="16">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many features are there of each data type?</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>feat_info[<span class="st">&#39;type&#39;</span>].value_counts()</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<pre><code>ordinal        49
categorical    21
numeric         7
mixed           7
interval        1
Name: type, dtype: int64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># But what are the types of the outliers (which have been dropped)?</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> feat_info.index:</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> feat_info.loc[i, <span class="st">&#39;attribute&#39;</span>] <span class="kw">in</span> outliers:</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{:&gt;25}{:&gt;25}</span><span class="st">&#39;</span>.<span class="bu">format</span>(feat_info.loc[i, <span class="st">&#39;attribute&#39;</span>], feat_info.loc[i, <span class="st">&#39;type&#39;</span>]))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                 AGER_TYP              categorical
              GEBURTSJAHR                  numeric
                 TITEL_KZ              categorical
                 ALTER_HH                 interval
             KK_KUNDENTYP              categorical
             KBA05_BAUMAX                    mixed
</code></pre>
</div>
</div>
<section id="step-121-re-encode-categorical-features"
class="cell markdown">
<h4>Step 1.2.1: Re-Encode Categorical Features</h4>
<p>For categorical data, you would ordinarily need to encode the levels
as dummy variables. Depending on the number of categories, perform one
of the following:</p>
<ul>
<li>For binary (two-level) categoricals that take numeric values, you
can keep them without needing to do anything.</li>
<li>There is one binary variable that takes on non-numeric values. For
this one, you need to re-encode the values as numbers or create a dummy
variable.</li>
<li>For multi-level categoricals (three or more values), you can choose
to encode the values using multiple dummy variables (e.g. via <a
href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">OneHotEncoder</a>),
or (to keep things straightforward) just drop them from the analysis. As
always, document your choices in the Discussion section.</li>
</ul>
</section>
<div class="cell code" data-execution_count="18">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assess categorical variables: which are binary, which are multi-level, and</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># which one needs to be re-encoded?</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="op">=</span> feat_info[feat_info[<span class="st">&#39;type&#39;</span>] <span class="op">==</span> <span class="st">&#39;categorical&#39;</span>][<span class="st">&#39;attribute&#39;</span>]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="op">=</span> <span class="bu">list</span>(categorical_features)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> categorical_features <span class="cf">if</span> c <span class="kw">not</span> <span class="kw">in</span> outliers]</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(categorical_features)) <span class="co"># 18 because there&#39;re 21 categorical features and 3 of them are outliers.</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>18
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="19">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking a look at the categorical features.</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>categorical_df <span class="op">=</span> azdias_clean[categorical_features].copy()</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>categorical_df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="19">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ANREDE_KZ</th>
      <th>CJT_GESAMTTYP</th>
      <th>FINANZTYP</th>
      <th>GFK_URLAUBERTYP</th>
      <th>GREEN_AVANTGARDE</th>
      <th>LP_FAMILIE_FEIN</th>
      <th>LP_FAMILIE_GROB</th>
      <th>LP_STATUS_FEIN</th>
      <th>LP_STATUS_GROB</th>
      <th>NATIONALITAET_KZ</th>
      <th>SHOPPER_TYP</th>
      <th>SOHO_KZ</th>
      <th>VERS_TYP</th>
      <th>ZABEOTYP</th>
      <th>GEBAEUDETYP</th>
      <th>OST_WEST_KZ</th>
      <th>CAMEO_DEUG_2015</th>
      <th>CAMEO_DEU_2015</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>5.0</td>
      <td>1</td>
      <td>10.0</td>
      <td>0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>5</td>
      <td>8.0</td>
      <td>W</td>
      <td>8</td>
      <td>8A</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>3.0</td>
      <td>1</td>
      <td>10.0</td>
      <td>1</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>5</td>
      <td>1.0</td>
      <td>W</td>
      <td>4</td>
      <td>4C</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>2.0</td>
      <td>6</td>
      <td>1.0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>3</td>
      <td>1.0</td>
      <td>W</td>
      <td>2</td>
      <td>2A</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>5.0</td>
      <td>5</td>
      <td>5.0</td>
      <td>0</td>
      <td>10.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>4</td>
      <td>1.0</td>
      <td>W</td>
      <td>6</td>
      <td>6B</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>2.0</td>
      <td>2</td>
      <td>1.0</td>
      <td>0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>4</td>
      <td>1.0</td>
      <td>W</td>
      <td>8</td>
      <td>8C</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigating categorical features: data types and number of different values.</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>n_categories <span class="op">=</span> categorical_df.nunique()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>categories_types <span class="op">=</span> categorical_df.dtypes</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>categories_info <span class="op">=</span> pd.concat([n_categories, categories_types], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>categories_info.rename(columns<span class="op">=</span>{<span class="dv">0</span>:<span class="st">&#39;n_categories&#39;</span>, <span class="dv">1</span>:<span class="st">&#39;dtype&#39;</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>categories_info</span></code></pre></div>
<div class="output execute_result" data-execution_count="20">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n_categories</th>
      <th>dtype</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ANREDE_KZ</th>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>CJT_GESAMTTYP</th>
      <td>6</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>FINANZTYP</th>
      <td>6</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>GFK_URLAUBERTYP</th>
      <td>12</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>GREEN_AVANTGARDE</th>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>LP_FAMILIE_FEIN</th>
      <td>11</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>LP_FAMILIE_GROB</th>
      <td>5</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>LP_STATUS_FEIN</th>
      <td>10</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>LP_STATUS_GROB</th>
      <td>5</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>NATIONALITAET_KZ</th>
      <td>3</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>SHOPPER_TYP</th>
      <td>4</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>SOHO_KZ</th>
      <td>2</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>VERS_TYP</th>
      <td>2</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ZABEOTYP</th>
      <td>6</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>GEBAEUDETYP</th>
      <td>7</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>OST_WEST_KZ</th>
      <td>2</td>
      <td>object</td>
    </tr>
    <tr>
      <th>CAMEO_DEUG_2015</th>
      <td>9</td>
      <td>object</td>
    </tr>
    <tr>
      <th>CAMEO_DEU_2015</th>
      <td>44</td>
      <td>object</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="21">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-encode categorical variable(s) to be kept in the analysis.</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># First, the binary non-numerical feature</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> handle_bi_non(df, bi_non, verbose<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(bi_non):</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&#39;</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(bi_non)<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>        two_cats <span class="op">=</span> df_copy[col].unique()</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&#39;Before: </span><span class="sc">{</span>two_cats<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>        df_copy[col] <span class="op">=</span> df_copy[col].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="dv">0</span> <span class="cf">if</span> x <span class="op">==</span> two_cats[<span class="dv">0</span>] <span class="cf">else</span> <span class="dv">1</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>        two_cats <span class="op">=</span> df_copy[col].unique()</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&#39;After: </span><span class="sc">{</span>two_cats<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> df_copy</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>bi_non <span class="op">=</span> [<span class="st">&#39;OST_WEST_KZ&#39;</span>]</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>data_cat_eng <span class="op">=</span> handle_bi_non(azdias_clean, bi_non)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>OST_WEST_KZ 1/1
Before: [&#39;W&#39; &#39;O&#39;]
After: [0 1]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="22">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Second, the multi-level categoricals</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>multilevel_info <span class="op">=</span> categories_info[categories_info[<span class="st">&#39;n_categories&#39;</span>] <span class="op">&gt;</span> <span class="dv">2</span>].copy()</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>multilevel_info.sort_values(<span class="st">&#39;n_categories&#39;</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>display(multilevel_info)</span></code></pre></div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n_categories</th>
      <th>dtype</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>NATIONALITAET_KZ</th>
      <td>3</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>SHOPPER_TYP</th>
      <td>4</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>LP_FAMILIE_GROB</th>
      <td>5</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>LP_STATUS_GROB</th>
      <td>5</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>CJT_GESAMTTYP</th>
      <td>6</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>FINANZTYP</th>
      <td>6</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ZABEOTYP</th>
      <td>6</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>GEBAEUDETYP</th>
      <td>7</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>CAMEO_DEUG_2015</th>
      <td>9</td>
      <td>object</td>
    </tr>
    <tr>
      <th>LP_STATUS_FEIN</th>
      <td>10</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>LP_FAMILIE_FEIN</th>
      <td>11</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>GFK_URLAUBERTYP</th>
      <td>12</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>CAMEO_DEU_2015</th>
      <td>44</td>
      <td>object</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="23">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>multilevel <span class="op">=</span> <span class="bu">list</span>(multilevel_info.index)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_multilevel(df, multilevel, plot_nr, plot_nc):</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    plt.subplots(plot_nr, plot_nc)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(multilevel):</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>        plt.subplot(plot_nr, plot_nc, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        sns.countplot(data<span class="op">=</span>df, x<span class="op">=</span>col)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>        plt.axhline(y<span class="op">=</span><span class="bu">int</span>(<span class="bu">len</span>(df)<span class="op">*</span><span class="fl">0.02</span>), color<span class="op">=</span><span class="st">&#39;r&#39;</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>show_multilevel(data_cat_eng, multilevel, <span class="dv">4</span>, <span class="dv">4</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/0dfa7b8edc41307a58bbdc869d9eb1a2ef8dd5a0.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="24">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Handling other multilevel categoricals.</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> handle_multilevel(df, to_binary, to_dummies, to_drop, threshold_to_bi):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col, th <span class="kw">in</span> <span class="bu">zip</span>(to_binary, threshold_to_bi):</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>        df_copy[col] <span class="op">=</span> df_copy[col].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="dv">0</span> <span class="cf">if</span> x <span class="op">&lt;</span> th <span class="cf">else</span> <span class="dv">1</span>)    </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.get_dummies(df_copy, columns<span class="op">=</span>to_dummies).drop(to_drop, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>to_binary <span class="op">=</span> [<span class="st">&#39;GEBAEUDETYP&#39;</span>]</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>to_drop <span class="op">=</span> [<span class="st">&#39;LP_STATUS_FEIN&#39;</span>, <span class="st">&#39;LP_FAMILIE_FEIN&#39;</span>, <span class="st">&#39;CAMEO_DEU_2015&#39;</span>]</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>to_dummies <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> multilevel <span class="cf">if</span> col <span class="kw">not</span> <span class="kw">in</span> to_binary<span class="op">+</span>to_drop]</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>threshold_to_bi <span class="op">=</span> [<span class="dv">3</span>]</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>data_after_dummies <span class="op">=</span> handle_multilevel(data_cat_eng, to_binary, to_dummies, to_drop, threshold_to_bi)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>data_after_dummies.shape  <span class="co"># (_, 123)</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="24">
<pre><code>(797077, 123)</code></pre>
</div>
</div>
<section id="discussion-121-re-encode-categorical-features"
class="cell markdown">
<h4>Discussion 1.2.1: Re-Encode Categorical Features</h4>
<p><em>(Double-click this cell and replace this text with your own text,
reporting your findings and decisions regarding categorical features.
Which ones did you keep, which did you drop, and what engineering steps
did you perform?)</em></p>
<p><strong>ANSWER:</strong> As shown in the graph above, there're 13
multilevel features, three of them (<em>LP_STATUS_FEIN</em>,
<em>LP_FAMILIE_FEIN</em> and <em>CAMEO_DEU_2015</em>) are detailed
versions of other three (<em>LP_STATUS_GROB</em>,
<em>LP_FAMILIE_GROB</em> and <em>CAMEO_DEUG_2015</em>). The problem with
the detailed three is not just they would be too overwhelming in the ML
processes, but most importantly their categories are not
well-represented in the demographics data at all, It's easy to notice
that by seeing many bars are under the horizontal red lines in the above
graphs (horizontal red lines point to 2% of the demographics), that
could lead to misguided results. So those three detailed features have
been dropped, and the three summarized features have been kept after
being converted to dummy variables.</p>
<p>Another case is the case of the <em>GEBAEUDETYP</em> feature, it has
8 different detailed classes while it just actually points to only two
different classes (type of building: resedential or commercial), the
over-detailed classes are not well-represented in the data, the clearest
example is the class labeled by 5 which is marked by only ONE data
sample in the whole dataset. This feature has been converted to a binary
feature, depending on information provided in
<code>Data_Dictionary.md</code>.</p>
<p>The other categorical features have been kept after being converted
to dummy variables.</p>
</section>
<section id="step-122-engineer-mixed-type-features"
class="cell markdown">
<h4>Step 1.2.2: Engineer Mixed-Type Features</h4>
<p>There are a handful of features that are marked as "mixed" in the
feature summary that require special treatment in order to be included
in the analysis. There are two in particular that deserve attention; the
handling of the rest are up to your own choices:</p>
<ul>
<li>"PRAEGENDE_JUGENDJAHRE" combines information on three dimensions:
generation by decade, movement (mainstream vs. avantgarde), and nation
(east vs. west). While there aren't enough levels to disentangle east
from west, you should create two new variables to capture the other two
dimensions: an interval-type variable for decade, and a binary variable
for movement.</li>
<li>"CAMEO_INTL_2015" combines information on two axes: wealth and life
stage. Break up the two-digit codes by their 'tens'-place and
'ones'-place digits into two new ordinal variables (which, for the
purposes of this project, is equivalent to just treating them as their
raw numeric values).</li>
<li>If you decide to keep or engineer new features around the other
mixed-type features, make sure you note your steps in the Discussion
section.</li>
</ul>
<p>Be sure to check <code>Data_Dictionary.md</code> for the details
needed to finish these tasks.</p>
</section>
<div class="cell code" data-execution_count="25">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigate &quot;PRAEGENDE_JUGENDJAHRE&quot; and engineer two new variables.</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co">From the Data_Dictionary.md file:</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co">-1: unknown</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">-  0: unknown</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">-  1: 40s - war years (Mainstream, E+W)</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co">-  2: 40s - reconstruction years (Avantgarde, E+W)</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co">-  3: 50s - economic miracle (Mainstream, E+W)</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co">-  4: 50s - milk bar / Individualisation (Avantgarde, E+W)</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co">-  5: 60s - economic miracle (Mainstream, E+W)</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co">-  6: 60s - generation 68 / student protestors (Avantgarde, W)</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co">-  7: 60s - opponents to the building of the Wall (Avantgarde, E)</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co">-  8: 70s - family orientation (Mainstream, E+W)</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="co">-  9: 70s - peace movement (Avantgarde, E+W)</span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="co">- 10: 80s - Generation Golf (Mainstream, W)</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co">- 11: 80s - ecological awareness (Avantgarde, W)</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="co">- 12: 80s - FDJ / communist party youth organisation (Mainstream, E)</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a><span class="co">- 13: 80s - Swords into ploughshares (Avantgarde, E)</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a><span class="co">- 14: 90s - digital media kids (Mainstream, E+W)</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co">- 15: 90s - ecological awareness (Avantgarde, E+W)</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mixed1(df):</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>    mainstream <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">14</span>]</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>    decades <span class="op">=</span> [<span class="va">None</span>, <span class="dv">40</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">60</span>, <span class="dv">60</span>, <span class="dv">70</span>, <span class="dv">70</span>, <span class="dv">80</span>, <span class="dv">80</span>, <span class="dv">80</span>, <span class="dv">80</span>, <span class="dv">90</span>, <span class="dv">90</span>]</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">&#39;MOVEMENT&#39;</span>] <span class="op">=</span> df_copy[<span class="st">&#39;PRAEGENDE_JUGENDJAHRE&#39;</span>].<span class="bu">apply</span>(<span class="op">\</span></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>                                            <span class="kw">lambda</span> x: x <span class="cf">if</span> np.isnan(x) <span class="cf">else</span> <span class="dv">1</span> <span class="cf">if</span> <span class="bu">int</span>(x) <span class="kw">in</span> mainstream <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">&#39;DECADES&#39;</span>] <span class="op">=</span> df_copy[<span class="st">&#39;PRAEGENDE_JUGENDJAHRE&#39;</span>].<span class="bu">apply</span>(<span class="op">\</span></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>                                            <span class="kw">lambda</span> x: x <span class="cf">if</span> np.isnan(x) <span class="cf">else</span> decades[<span class="bu">int</span>(x)]<span class="op">//</span><span class="dv">10</span> <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy.drop(<span class="st">&#39;PRAEGENDE_JUGENDJAHRE&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>data_1st_inv <span class="op">=</span> mixed1(data_after_dummies)</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>data_1st_inv.shape <span class="co"># (_, 123 + 2 new features - 1 dropped features = 124)</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="25">
<pre><code>(797077, 124)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="26">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigate &quot;CAMEO_INTL_2015&quot; and engineer two new variables.</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">From the Data_Dictionary.md file:</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">- -1: unknown</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co">- 11: Wealthy Households - Pre-Family Couples &amp; Singles</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co">- 12: Wealthy Households - Young Couples With Children</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co">- 13: Wealthy Households - Families With School Age Children</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co">- 14: Wealthy Households - Older Families &amp;  Mature Couples</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co">- 15: Wealthy Households - Elders In Retirement</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co">- 21: Prosperous Households - Pre-Family Couples &amp; Singles</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="co">- 22: Prosperous Households - Young Couples With Children</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="co">- 23: Prosperous Households - Families With School Age Children</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="co">- 24: Prosperous Households - Older Families &amp; Mature Couples</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="co">- 25: Prosperous Households - Elders In Retirement</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a><span class="co">- 31: Comfortable Households - Pre-Family Couples &amp; Singles</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="co">- 32: Comfortable Households - Young Couples With Children</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="co">- 33: Comfortable Households - Families With School Age Children</span></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="co">- 34: Comfortable Households - Older Families &amp; Mature Couples</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="co">- 35: Comfortable Households - Elders In Retirement</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a><span class="co">- 41: Less Affluent Households - Pre-Family Couples &amp; Singles</span></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a><span class="co">- 42: Less Affluent Households - Young Couples With Children</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a><span class="co">- 43: Less Affluent Households - Families With School Age Children</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a><span class="co">- 44: Less Affluent Households - Older Families &amp; Mature Couples</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a><span class="co">- 45: Less Affluent Households - Elders In Retirement</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a><span class="co">- 51: Poorer Households - Pre-Family Couples &amp; Singles</span></span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a><span class="co">- 52: Poorer Households - Young Couples With Children</span></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a><span class="co">- 53: Poorer Households - Families With School Age Children</span></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a><span class="co">- 54: Poorer Households - Older Families &amp; Mature Couples</span></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a><span class="co">- 55: Poorer Households - Elders In Retirement</span></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a><span class="co">- XX: unknown</span></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mixed2(df):</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># here I&#39;ll use type(x) != str instead of isnan(x) because isnan() doesn&#39;t accept strings as input.</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">&#39;CAMEO_INTL_2015_dig1&#39;</span>] <span class="op">=</span> df_copy[<span class="st">&#39;CAMEO_INTL_2015&#39;</span>].<span class="bu">apply</span>(<span class="op">\</span></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>                                                            <span class="kw">lambda</span> x: np.nan <span class="cf">if</span> <span class="bu">type</span>(x) <span class="op">!=</span> <span class="bu">str</span> <span class="cf">else</span> <span class="bu">int</span>(x)<span class="op">//</span><span class="dv">10</span>)</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">&#39;CAMEO_INTL_2015_dig2&#39;</span>] <span class="op">=</span> df_copy[<span class="st">&#39;CAMEO_INTL_2015&#39;</span>].<span class="bu">apply</span>(<span class="op">\</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>                                                            <span class="kw">lambda</span> x: np.nan <span class="cf">if</span> <span class="bu">type</span>(x) <span class="op">!=</span> <span class="bu">str</span> <span class="cf">else</span> <span class="bu">int</span>(x)<span class="op">%</span><span class="dv">10</span>)</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy.drop(<span class="st">&#39;CAMEO_INTL_2015&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>data_2nd_inv <span class="op">=</span> mixed2(data_1st_inv)</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>data_2nd_inv.shape <span class="co"># (_, 124 + 2 new features - 1 dropped feature = 125)</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="26">
<pre><code>(797077, 125)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="27">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigating other mixed features</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># From out[18] there&#39;re 7 mixed features, 1 of them is an outlier and 2 of them have been handled already</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># So there&#39;re 4 mixed features remaining.</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>handled <span class="op">=</span> [<span class="st">&#39;PRAEGENDE_JUGENDJAHRE&#39;</span>, <span class="st">&#39;CAMEO_INTL_2015&#39;</span>]</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>mixed_features <span class="op">=</span> <span class="bu">list</span>(feat_info[feat_info[<span class="st">&#39;type&#39;</span>] <span class="op">==</span> <span class="st">&#39;mixed&#39;</span>][<span class="st">&#39;attribute&#39;</span>])</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>mixed_features <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> mixed_features <span class="cf">if</span> f <span class="kw">not</span> <span class="kw">in</span> handled<span class="op">+</span>outliers]</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>mixed_features</span></code></pre></div>
<div class="output execute_result" data-execution_count="27">
<pre><code>[&#39;LP_LEBENSPHASE_FEIN&#39;, &#39;LP_LEBENSPHASE_GROB&#39;, &#39;WOHNLAGE&#39;, &#39;PLZ8_BAUMAX&#39;]</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="28">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigating LP_LEBENSPHASE_FEIN and LP_LEBENSPHASE_GROB</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Both of them describe life stage in fine and rough scale respectively</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># But this information is included in other features already</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mixed3(df):</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df.drop([<span class="st">&#39;LP_LEBENSPHASE_FEIN&#39;</span>, <span class="st">&#39;LP_LEBENSPHASE_GROB&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>data_3rd_inv <span class="op">=</span> mixed3(data_2nd_inv)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>data_3rd_inv.shape <span class="co"># (_, 125 - 2 = 123)</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="28">
<pre><code>(797077, 123)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="29">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigating WOHNLAGE</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>display(data_3rd_inv[<span class="st">&#39;WOHNLAGE&#39;</span>].value_counts())</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># WOHNLAGE is an ordinal feature from 1 to 6 that describes the quality of neighborhood</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co"># When it&#39;s 7 or 8 it becomes a rural flag</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mixed4(df):</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    is_rural <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="kw">in</span> [<span class="dv">7</span>, <span class="dv">8</span>] <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">&#39;WOHNLAGE_RURAL&#39;</span>] <span class="op">=</span> df_copy[<span class="st">&#39;WOHNLAGE&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x <span class="cf">if</span> np.isnan(x) <span class="cf">else</span> is_rural(x))</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy.drop(<span class="st">&#39;WOHNLAGE&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>data_4th_inv <span class="op">=</span> mixed4(data_3rd_inv)</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>data_4th_inv.shape <span class="co"># (_, 123 + 1 - 1 = 123)</span></span></code></pre></div>
<div class="output display_data">
<pre><code>3.0    249537
7.0    169238
4.0    135867
2.0    100303
5.0     74274
1.0     43876
8.0     17356
0.0      6626
Name: WOHNLAGE, dtype: int64</code></pre>
</div>
<div class="output execute_result" data-execution_count="29">
<pre><code>(797077, 123)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="30">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigating PLZ8_BAUMAX</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>display(data_4th_inv[<span class="st">&#39;PLZ8_BAUMAX&#39;</span>].value_counts())</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># PLZ8_BAUMAX is an ordinal feature from 1 to 4 that describes number of family homes around</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Only when it&#39;s 5 it becomes a business buildings flag</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mixed5(df):</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>    get_fhomes <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="op">==</span> <span class="dv">5</span> <span class="cf">else</span> x</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>    is_business <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="op">==</span> <span class="dv">5</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">&#39;PLZ8_FAMILY_HOMES&#39;</span>] <span class="op">=</span> df_copy[<span class="st">&#39;PLZ8_BAUMAX&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x <span class="cf">if</span> np.isnan(x) <span class="cf">else</span> get_fhomes(x))</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">&#39;PLZ8_BUSINESS&#39;</span>] <span class="op">=</span> df_copy[<span class="st">&#39;PLZ8_BAUMAX&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x <span class="cf">if</span> np.isnan(x) <span class="cf">else</span> is_business(x))</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy.drop(<span class="st">&#39;PLZ8_BAUMAX&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>data_5th_inv <span class="op">=</span> mixed5(data_4th_inv)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>data_5th_inv.shape <span class="co"># (_, 123 + 2 - 1 = 124)</span></span></code></pre></div>
<div class="output display_data">
<pre><code>1.0    499540
5.0     97333
2.0     70406
4.0     56684
3.0     50732
Name: PLZ8_BAUMAX, dtype: int64</code></pre>
</div>
<div class="output execute_result" data-execution_count="30">
<pre><code>(797077, 124)</code></pre>
</div>
</div>
<section id="discussion-122-engineer-mixed-type-features"
class="cell markdown">
<h4>Discussion 1.2.2: Engineer Mixed-Type Features</h4>
<p><em>(Double-click this cell and replace this text with your own text,
reporting your findings and decisions regarding mixed-value features.
Which ones did you keep, which did you drop, and what engineering steps
did you perform?)</em></p>
<p><strong>ANSWER:</strong> As seen before, there're 7 mixed-type
features, two of them have been already handled and one of them has been
dropped as an outlier, that makes only four mixed-type features remain,
which are: <em>LP_LEBENSPHASE_FEIN</em>, <em>LP_LEBENSPHASE_GROB</em>,
<em>WOHNLAGE</em> and <em>PLZ8_BAUMAX</em>.</p>
<p>The first two are rough and fine versions of the same data, which
represnt information like family flag, single/not flag and income
categories, but this information is already included in other features,
so I dropped these two features. This is done in the function
<code>mixed3()</code>.</p>
<p>The third feature is an ordinal variable that describes the
neighborhood quality when it's between (and included) 1 and 6, but when
it's 7 or 8 then it's a rural flag, while 0 means no score is
calculated. I extracted a rural flag from this feature, but extracting
quality score won't be very efficient, since labels 0, 7 and 8 don't
provide any information about such score, that would make the quality
score feature an outlier column with so many missing values. That ends
up with this feature having only a rural flag. This is done in the
function <code>mixed4()</code></p>
<p>The fourth feature is an interval variable that represents how many
family homes are around, but only when it's 5 it becomes a flag of
business building around. I extracted two engineered features as
follows:</p>
<ul>
<li><em>PLZ8_FAMILY_HOMES</em>: An interval feature takes value from 1
to 5. 1 means no, 1 or 2 family homes around and 5 means the most
possible number of family homes in the area.</li>
<li><em>PLZ8_BUSINESS</em>: A binary categorical that determines if it's
a mainly business buldings area or not.</li>
</ul>
<p>This is done in the function <code>mixed5()</code>.</p>
</section>
<section id="step-123-complete-feature-selection" class="cell markdown">
<h4>Step 1.2.3: Complete Feature Selection</h4>
<p>In order to finish this step up, you need to make sure that your data
frame now only has the columns that you want to keep. To summarize, the
dataframe should consist of the following:</p>
<ul>
<li>All numeric, interval, and ordinal type columns from the original
dataset.</li>
<li>Binary categorical features (all numerically-encoded).</li>
<li>Engineered features from other multi-level categorical features and
mixed features.</li>
</ul>
<p>Make sure that for any new columns that you have engineered, that
you've excluded the original columns from the final dataset. Otherwise,
their values will interfere with the analysis later on the project. For
example, you should not keep "PRAEGENDE_JUGENDJAHRE", since its values
won't be useful for the algorithm: only the values derived from it in
the engineered features you created should be retained. As a reminder,
your data should only be from <strong>the subset with few or no missing
values</strong>.</p>
</section>
<div class="cell code" data-execution_count="31">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If there are other re-engineering tasks you need to perform, make sure you</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="co"># take care of them here. (Dealing with missing data will come in step 2.1.)</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Nothing to do</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="32">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Do whatever you need to in order to ensure that the dataframe only contains</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the columns that should be passed to the algorithm functions.</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Nothing to do</span></span></code></pre></div>
</div>
<section id="step-13-create-a-cleaning-function" class="cell markdown">
<h3>Step 1.3: Create a Cleaning Function</h3>
<p>Even though you've finished cleaning up the general population
demographics data, it's important to look ahead to the future and
realize that you'll need to perform the same cleaning steps on the
customer demographics data. In this substep, complete the function below
to execute the main feature selection, encoding, and re-engineering
steps you performed above. Then, when it comes to looking at the
customer data in Step 3, you can just run this function on that
DataFrame to get the trimmed dataset in a single step.</p>
</section>
<div class="cell code" data-execution_count="34">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_data(df, feat_info, outliers, threshold, bi_non, to_dummies, to_drop, threshold_to_bi):</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Perform feature trimming, re-encoding, and engineering for demographics</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co">    data</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="co">    INPUT: Demographics DataFrame</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="co">    OUTPUT: Trimmed and cleaned demographics DataFrame</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Put in code here to execute all main cleaning steps:</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert missing value codes into NaNs, ...</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;Converting all missed data to NaNs...&#39;</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>    df_with_missing <span class="op">=</span> to_nan(df, feat_info, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove selected columns and rows, ...</span></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;Removing messy columns and rows...&#39;</span>)</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>    df_without_outliers <span class="op">=</span> remove_outlier_cols(df_with_missing, outliers)</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>    df_clean, _ <span class="op">=</span> split_messy_rows(df_without_outliers, threshold)</span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Number of columns now is </span><span class="sc">{</span>df_clean<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, should be 79&#39;</span>)</span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># select, re-encode, and engineer column values.</span></span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;Selecting, re-encoding and engineering...&#39;</span>)</span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a>    data_cat_eng <span class="op">=</span> handle_bi_non(df_clean, bi_non)</span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a>    data_after_dummies <span class="op">=</span> handle_multilevel(data_cat_eng, to_binary, to_dummies, to_drop, threshold_to_bi)</span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Number of columns now is </span><span class="sc">{</span>data_after_dummies<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, should be 123&#39;</span>)</span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a>    data_1st_inv <span class="op">=</span> mixed1(data_after_dummies)</span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Number of columns now is </span><span class="sc">{</span>data_1st_inv<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, should be 124&#39;</span>)</span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a>    data_2nd_inv <span class="op">=</span> mixed2(data_1st_inv)</span>
<span id="cb56-32"><a href="#cb56-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Number of columns now is </span><span class="sc">{</span>data_2nd_inv<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, should be 125&#39;</span>)</span>
<span id="cb56-33"><a href="#cb56-33" aria-hidden="true" tabindex="-1"></a>    data_3rd_inv <span class="op">=</span> mixed3(data_2nd_inv)</span>
<span id="cb56-34"><a href="#cb56-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Number of columns now is </span><span class="sc">{</span>data_3rd_inv<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, should be 123&#39;</span>)</span>
<span id="cb56-35"><a href="#cb56-35" aria-hidden="true" tabindex="-1"></a>    data_4th_inv <span class="op">=</span> mixed4(data_3rd_inv)</span>
<span id="cb56-36"><a href="#cb56-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Number of columns now is </span><span class="sc">{</span>data_4th_inv<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, should be 123&#39;</span>)</span>
<span id="cb56-37"><a href="#cb56-37" aria-hidden="true" tabindex="-1"></a>    data_5th_inv <span class="op">=</span> mixed5(data_4th_inv)</span>
<span id="cb56-38"><a href="#cb56-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Number of columns now is </span><span class="sc">{</span>data_5th_inv<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">, should be 124&#39;</span>)</span>
<span id="cb56-39"><a href="#cb56-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-40"><a href="#cb56-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-41"><a href="#cb56-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the cleaned dataframe.</span></span>
<span id="cb56-42"><a href="#cb56-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Returning df_clean also because it&#39;s the version with the original columns</span></span>
<span id="cb56-43"><a href="#cb56-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># That will make using inverse_transform() methods unnecessary</span></span>
<span id="cb56-44"><a href="#cb56-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_5th_inv, df_clean</span>
<span id="cb56-45"><a href="#cb56-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-46"><a href="#cb56-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-47"><a href="#cb56-47" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> data_5th_inv.shape <span class="op">==</span> clean_data(azdias, feat_info, outliers, threshold, bi_non,</span>
<span id="cb56-48"><a href="#cb56-48" aria-hidden="true" tabindex="-1"></a>                                  to_dummies, to_drop, threshold_to_bi)[<span class="dv">0</span>].shape</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Converting all missed data to NaNs...
Removing messy columns and rows...
Number of columns now is 79, should be 79
Selecting, re-encoding and engineering...
OST_WEST_KZ 1/1
Before: [&#39;W&#39; &#39;O&#39;]
After: [0 1]
Number of columns now is 123, should be 123
Number of columns now is 124, should be 124
Number of columns now is 125, should be 125
Number of columns now is 123, should be 123
Number of columns now is 123, should be 123
Number of columns now is 124, should be 124
</code></pre>
</div>
</div>
<section id="step-2-feature-transformation" class="cell markdown">
<h2>Step 2: Feature Transformation</h2>
<h3 id="step-21-apply-feature-scaling">Step 2.1: Apply Feature
Scaling</h3>
<p>Before we apply dimensionality reduction techniques to the data, we
need to perform feature scaling so that the principal component vectors
are not influenced by the natural differences in scale for features.
Starting from this part of the project, you'll want to keep an eye on
the <a href="http://scikit-learn.org/stable/modules/classes.html">API
reference page for sklearn</a> to help you navigate to all of the
classes and functions that you'll need. In this substep, you'll need to
check the following:</p>
<ul>
<li>sklearn requires that data not have missing values in order for its
estimators to work properly. So, before applying the scaler to your
data, make sure that you've cleaned the DataFrame of the remaining
missing values. This can be as simple as just removing all data points
with missing data, or applying an <a
href="https://scikit-learn.org/0.16/modules/generated/sklearn.preprocessing.Imputer.html">Imputer</a>
to replace all missing values. You might also try a more complicated
procedure where you temporarily remove missing values in order to
compute the scaling parameters before re-introducing those missing
values and applying imputation. Think about how much missing data you
have and what possible effects each approach might have on your
analysis, and justify your decision in the discussion section
below.</li>
<li>For the actual scaling function, a <a
href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">StandardScaler</a>
instance is suggested, scaling each feature to mean 0 and standard
deviation 1.</li>
<li>For these classes, you can make use of the
<code>.fit_transform()</code> method to both fit a procedure to the data
as well as apply the transformation to the data at the same time. Don't
forget to keep the fit sklearn objects handy, since you'll be applying
them to the customer demographics data towards the end of the
project.</li>
</ul>
</section>
<div class="cell code" data-execution_count="35">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If you&#39;ve not yet cleaned the dataset of all NaN values, then investigate and</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="co"># do that now.</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>nan_info(data_5th_inv)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>There are 790760 missing values. (0.8001%).
There are 173866 rows with missing values. (21.81%).
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="36">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Since missing data is less than 1%, a quick imputation might be fine!</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> Imputer</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_impute(df, model<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If no model is passed as an argument, the function will create one</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>    imputer_model <span class="op">=</span> model <span class="cf">if</span> model <span class="cf">else</span> Imputer()</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If a trained model is passed as an argument then only transform() will be used, otherwise fit_transform()</span></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>    imputed_data <span class="op">=</span> imputer_model.transform(df) <span class="cf">if</span> model <span class="cf">else</span> imputer_model.fit_transform(df)</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>    imputed_data <span class="op">=</span> pd.DataFrame(imputed_data, columns <span class="op">=</span> data_5th_inv.columns)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ignore the first return value if a trained model has been passed already</span></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> imputer_model, imputed_data</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>imputer_model, imputed_data <span class="op">=</span> do_impute(data_5th_inv)</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>nan_info(imputed_data)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>There are 0 missing values. (0.0%).
There are 0 rows with missing values. (0.0%).
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="37">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply feature scaling to the general population demographics data.</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_scale(df, model<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If no model is passed as an argument, the function will create one</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    scaler_model <span class="op">=</span> model <span class="cf">if</span> model <span class="cf">else</span> StandardScaler()</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If a trained model is passed as an argument then only transform() will be used, otherwise fit_transform()</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    scaled_data <span class="op">=</span> scaler_model.transform(df) <span class="cf">if</span> model <span class="cf">else</span> scaler_model.fit_transform(df)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    scaled_data <span class="op">=</span> pd.DataFrame(scaled_data, columns <span class="op">=</span> imputed_data.columns)</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ignore the first return value if a trained model has been passed already</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> scaler_model, scaled_data</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>scaler_model, scaled_data <span class="op">=</span> do_scale(imputed_data)</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>scaled_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="37">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ALTERSKATEGORIE_GROB</th>
      <th>ANREDE_KZ</th>
      <th>FINANZ_MINIMALIST</th>
      <th>FINANZ_SPARER</th>
      <th>FINANZ_VORSORGER</th>
      <th>FINANZ_ANLEGER</th>
      <th>FINANZ_UNAUFFAELLIGER</th>
      <th>FINANZ_HAUSBAUER</th>
      <th>GREEN_AVANTGARDE</th>
      <th>HEALTH_TYP</th>
      <th>...</th>
      <th>GFK_URLAUBERTYP_10.0</th>
      <th>GFK_URLAUBERTYP_11.0</th>
      <th>GFK_URLAUBERTYP_12.0</th>
      <th>MOVEMENT</th>
      <th>DECADES</th>
      <th>CAMEO_INTL_2015_dig1</th>
      <th>CAMEO_INTL_2015_dig2</th>
      <th>WOHNLAGE_RURAL</th>
      <th>PLZ8_FAMILY_HOMES</th>
      <th>PLZ8_BUSINESS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.765596</td>
      <td>0.958121</td>
      <td>-1.494463</td>
      <td>1.538139</td>
      <td>-1.040664</td>
      <td>1.466401</td>
      <td>0.959974</td>
      <td>1.338532</td>
      <td>-0.530654</td>
      <td>1.085338</td>
      <td>...</td>
      <td>2.599537</td>
      <td>-0.322405</td>
      <td>-0.441418</td>
      <td>0.553082</td>
      <td>1.165504</td>
      <td>1.190696</td>
      <td>-1.265981</td>
      <td>-0.552856</td>
      <td>-0.495438</td>
      <td>-0.384507</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.201448</td>
      <td>0.958121</td>
      <td>-1.494463</td>
      <td>0.864753</td>
      <td>-1.766903</td>
      <td>-0.570914</td>
      <td>0.245238</td>
      <td>1.338532</td>
      <td>1.884467</td>
      <td>1.085338</td>
      <td>...</td>
      <td>2.599537</td>
      <td>-0.322405</td>
      <td>-0.441418</td>
      <td>-1.874665</td>
      <td>1.165504</td>
      <td>-0.865318</td>
      <td>0.761849</td>
      <td>-0.552856</td>
      <td>-0.495438</td>
      <td>-0.384507</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.184971</td>
      <td>0.958121</td>
      <td>0.683285</td>
      <td>-0.482020</td>
      <td>1.138052</td>
      <td>-0.570914</td>
      <td>-1.184235</td>
      <td>-0.792444</td>
      <td>-0.530654</td>
      <td>-0.270203</td>
      <td>...</td>
      <td>-0.384684</td>
      <td>-0.322405</td>
      <td>-0.441418</td>
      <td>0.553082</td>
      <td>-0.231903</td>
      <td>-1.550656</td>
      <td>-0.590038</td>
      <td>1.808789</td>
      <td>-0.495438</td>
      <td>-0.384507</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.201448</td>
      <td>-1.043709</td>
      <td>0.683285</td>
      <td>0.191366</td>
      <td>0.411813</td>
      <td>-1.250019</td>
      <td>0.245238</td>
      <td>-0.792444</td>
      <td>-0.530654</td>
      <td>1.085338</td>
      <td>...</td>
      <td>-0.384684</td>
      <td>-0.322405</td>
      <td>-0.441418</td>
      <td>0.553082</td>
      <td>-0.231903</td>
      <td>0.505358</td>
      <td>0.085906</td>
      <td>-0.552856</td>
      <td>0.627079</td>
      <td>-0.384507</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.765596</td>
      <td>0.958121</td>
      <td>-0.042631</td>
      <td>-1.155407</td>
      <td>1.138052</td>
      <td>-0.570914</td>
      <td>-0.469499</td>
      <td>1.338532</td>
      <td>-0.530654</td>
      <td>1.085338</td>
      <td>...</td>
      <td>-0.384684</td>
      <td>-0.322405</td>
      <td>-0.441418</td>
      <td>0.553082</td>
      <td>-1.629311</td>
      <td>1.190696</td>
      <td>0.761849</td>
      <td>1.808789</td>
      <td>-0.495438</td>
      <td>-0.384507</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 124 columns</p>
</div>
</div>
</div>
<section id="discussion-21-apply-feature-scaling" class="cell markdown">
<h3>Discussion 2.1: Apply Feature Scaling</h3>
<p>(Double-click this cell and replace this text with your own text,
reporting your decisions regarding feature scaling.)</p>
<p><strong>ANSWER:</strong> Since the missing values are less than 1% of
the data, A complex approach would not be very necessary, so I chose a
quick imputation before feature scaling. Maybe dropping rows with
missing value was also a fine option but I prefered to have
<em>imputer_model</em> that may be useful later.</p>
<p>I also used StandardScaler class to make every thing in the data
frame with mean of zero and standard deviation of one.</p>
</section>
<section id="step-22-perform-dimensionality-reduction"
class="cell markdown">
<h3>Step 2.2: Perform Dimensionality Reduction</h3>
<p>On your scaled data, you are now ready to apply dimensionality
reduction techniques.</p>
<ul>
<li>Use sklearn's <a
href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">PCA</a>
class to apply principal component analysis on the data, thus finding
the vectors of maximal variance in the data. To start, you should not
set any parameters (so all components are computed) or set a number of
components that is at least half the number of features (so there's
enough features to see the general trend in variability).</li>
<li>Check out the ratio of variance explained by each principal
component as well as the cumulative variance explained. Try plotting the
cumulative or sequential values using matplotlib's <a
href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html"><code>plot()</code></a>
function. Based on what you find, select a value for the number of
transformed features you'll retain for the clustering part of the
project.</li>
<li>Once you've made a choice for the number of components to keep, make
sure you re-fit a PCA instance to perform the decided-on
transformation.</li>
</ul>
</section>
<div class="cell code" data-execution_count="38">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA to the data.</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_pca(df, n_components<span class="op">=</span><span class="dv">120</span>, model<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If no model is passed as an argument, the function will create one depending on n_components</span></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    pca_model <span class="op">=</span> model <span class="cf">if</span> model <span class="cf">else</span> PCA(n_components<span class="op">=</span>n_components) </span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>    before <span class="op">=</span> time()</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If a trained model is passed as an argument, then only transform() will be used, otherwise fit_transform()</span></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>    data_after_pca <span class="op">=</span> pca_model.transform(df) <span class="cf">if</span> model <span class="cf">else</span> pca_model.fit_transform(df)</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>    time_taken <span class="op">=</span> time() <span class="op">-</span> before</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Time taken: </span><span class="sc">{</span><span class="bu">int</span>(time_taken<span class="op">//</span><span class="dv">60</span>)<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span><span class="bu">int</span>(time_taken<span class="op">%</span><span class="dv">60</span>)<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ignore the first return value if a trained model has been passed already</span></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pca_model, data_after_pca</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>pca_model, data_after_pca <span class="op">=</span> do_pca(scaled_data, n_components<span class="op">=</span><span class="dv">80</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Time taken: 1:11
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="39">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigate the variance accounted for by each principal component.</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_pca(pca_model, good_ratio<span class="op">=</span><span class="fl">0.9</span>):</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    variances <span class="op">=</span> <span class="bu">list</span>(pca_model.explained_variance_ratio_)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>    cumulative_variances <span class="op">=</span> <span class="bu">list</span>(pca_model.explained_variance_ratio_.cumsum())</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    comp_index <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(variances)))</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    plt.rcParams[<span class="st">&quot;figure.figsize&quot;</span>] <span class="op">=</span> (<span class="dv">20</span>,<span class="dv">7</span>)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>    plt.bar(comp_index, variances)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Variance&#39;</span>)</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    plt.bar(comp_index, cumulative_variances)</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    plt.axhline(y<span class="op">=</span>good_ratio, color<span class="op">=</span><span class="st">&#39;g&#39;</span>)</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Principal Components&#39;</span>)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Cumulative Variance&#39;</span>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>plot_pca(pca_model)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/81253bf259b2d036438a7e54371b07b60eb7421b.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="40">
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s see when components pass 90%</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>cumulative_variances <span class="op">=</span> <span class="bu">list</span>(pca_model.explained_variance_ratio_.cumsum())</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>n_components_less_90 <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: x<span class="op">&lt;</span><span class="fl">0.9</span>, cumulative_variances)))</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;There are </span><span class="sc">{</span>n_components_less_90<span class="sc">}</span><span class="ss"> compnents that their cumulative variance is less than 90%&#39;</span>)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Component </span><span class="sc">{</span>n_components_less_90 <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> has cumulative variance = </span><span class="sc">{</span>cumulative_variances[n_components_less_90]<span class="sc">}</span><span class="ss">.&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>There are 67 compnents that their cumulative variance is less than 90%
Component 68 has cumulative variance = 0.9028737522733454.
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="41">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-apply PCA to the data while selecting for number of components to retain.</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>pca_model, data_after_pca <span class="op">=</span> do_pca(scaled_data, <span class="dv">68</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Time taken: 1:5
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="42">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the new PCA model.</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>plot_pca(pca_model)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/4734fefd41ff37d1c3a90efb950d28dcc7a5f444.png" /></p>
</div>
</div>
<section id="discussion-22-perform-dimensionality-reduction"
class="cell markdown">
<h3>Discussion 2.2: Perform Dimensionality Reduction</h3>
<p>(Double-click this cell and replace this text with your own text,
reporting your findings and decisions regarding dimensionality
reduction. How many principal components / transformed features are you
retaining for the next step of the analysis?)</p>
<p><strong>ANSWER:</strong> Initially, I reduced the dimensions from 124
to 80, then plotting and investigating the principal components showed
that only 68 components are enough to keep +90% of the variability. So
the final choice is 68.</p>
</section>
<section id="step-23-interpret-principal-components"
class="cell markdown">
<h3>Step 2.3: Interpret Principal Components</h3>
<p>Now that we have our transformed principal components, it's a nice
idea to check out the weight of each variable on the first few
components to see if they can be interpreted in some fashion.</p>
<p>As a reminder, each principal component is a unit vector that points
in the direction of highest variance (after accounting for the variance
captured by earlier principal components). The further a weight is from
zero, the more the principal component is in the direction of the
corresponding feature. If two features have large weights of the same
sign (both positive or both negative), then increases in one tend expect
to be associated with increases in the other. To contrast, features with
different signs can be expected to show a negative correlation:
increases in one variable should result in a decrease in the other.</p>
<ul>
<li>To investigate the features, you should map each weight to their
corresponding feature name, then sort the features according to weight.
The most interesting features for each principal component, then, will
be those at the beginning and end of the sorted list. Use the data
dictionary document to help you understand these most prominent
features, their relationships, and what a positive or negative value on
the principal component might indicate.</li>
<li>You should investigate and interpret feature associations from the
first three principal components in this substep. To help facilitate
this, you should write a function that you can call at any time to print
the sorted list of feature weights, for the <em>i</em>-th principal
component. This might come in handy in the next step of the project,
when you interpret the tendencies of the discovered clusters.</li>
</ul>
</section>
<div class="cell code" data-execution_count="58">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Map weights for the first principal component to corresponding feature names</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and then print the linked values, sorted by weight.</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="co"># HINT: Try defining a function here or in a new cell that you can reuse in the</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="co"># other cells.</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> map_weights(pca_model, feature_names, component_ind):</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    component_weights <span class="op">=</span> <span class="bu">list</span>(pca_model.components_[component_ind])</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>    weights_dict <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(feature_names, component_weights))</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>    weights_dict <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">sorted</span>(weights_dict.items(), key<span class="op">=</span> <span class="kw">lambda</span> x: <span class="op">-</span><span class="bu">abs</span>(x[<span class="dv">1</span>])))</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weights_dict</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_dict(d, n):</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, k <span class="kw">in</span> <span class="bu">enumerate</span>(d):</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">==</span> n:</span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{:&gt;25}{:&gt;25}</span><span class="st">&#39;</span>.<span class="bu">format</span>(k, d[k]))</span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_weighted_features(d, n):</span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(d.items()), columns<span class="op">=</span>[<span class="st">&#39;Features&#39;</span>, <span class="st">&#39;Weights&#39;</span>])</span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>    df_pve <span class="op">=</span> df[df[<span class="st">&#39;Weights&#39;</span>] <span class="op">&gt;=</span> <span class="dv">0</span>]</span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>    df_nve <span class="op">=</span> df[df[<span class="st">&#39;Weights&#39;</span>] <span class="op">&lt;</span> <span class="dv">0</span>]</span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>    df_to_plot <span class="op">=</span> pd.concat([df_pve[:n], df_nve[:n]], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>    df_to_plot.plot.bar(x<span class="op">=</span><span class="st">&#39;Features&#39;</span>, y<span class="op">=</span><span class="st">&#39;Weights&#39;</span>, color<span class="op">=</span>[<span class="st">&#39;blue&#39;</span>]<span class="op">*</span>n<span class="op">+</span>[<span class="st">&#39;red&#39;</span>]<span class="op">*</span>n)</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> <span class="bu">list</span>(scaled_data.columns)</span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a>first_component <span class="op">=</span> map_weights(pca_model, feature_names, <span class="dv">0</span>)</span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a>show_weighted_features(first_component, <span class="dv">5</span>)</span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a><span class="co"># print_dict(first_component, 20)</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/db6203df3495b91db7566db56a4a9dec9c8025b3.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="59">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Map weights for the second principal component to corresponding feature names</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and then print the linked values, sorted by weight.</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>second_component <span class="op">=</span> map_weights(pca_model, feature_names, <span class="dv">1</span>)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>show_weighted_features(second_component, <span class="dv">5</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/c5112d7dfe44599c70077ffa4a5b988331475d70.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="62">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Map weights for the third principal component to corresponding feature names</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and then print the linked values, sorted by weight.</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>third_component <span class="op">=</span> map_weights(pca_model, feature_names, <span class="dv">2</span>)</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>show_weighted_features(third_component, <span class="dv">5</span>)</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/6c44e1a445a10066c1f6522633fa62394e2b62d5.png" /></p>
</div>
</div>
<section id="discussion-23-interpret-principal-components"
class="cell markdown">
<h3>Discussion 2.3: Interpret Principal Components</h3>
<p>(Double-click this cell and replace this text with your own text,
reporting your observations from detailed investigation of the first few
principal components generated. Can we interpret positive and negative
values from them in a meaningful way?)</p>
<p><strong>ANSWER:</strong> Yes, we can interpret positive and negative
values from them in a meaningful way. For example, in the second
component the greatest weights are given to <em>DECADES</em> and
<em>ALTERSKATEGORIE_GROB</em> but in inverted signs. The first feature
points to the decade of the dominent movement of person's generation (0
means the decade of 1940s and so on to 6 which means 1990s) and the
second features is the estimated age feature, the inverse relation
between the two features is clear.</p>
</section>
<section id="step-3-clustering" class="cell markdown">
<h2>Step 3: Clustering</h2>
<h3 id="step-31-apply-clustering-to-general-population">Step 3.1: Apply
Clustering to General Population</h3>
<p>You've assessed and cleaned the demographics data, then scaled and
transformed them. Now, it's time to see how the data clusters in the
principal components space. In this substep, you will apply k-means
clustering to the dataset and use the average within-cluster distances
from each point to their assigned cluster's centroid to decide on a
number of clusters to keep.</p>
<ul>
<li>Use sklearn's <a
href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans">KMeans</a>
class to perform k-means clustering on the PCA-transformed data.</li>
<li>Then, compute the average difference from each point to its assigned
cluster's center. <strong>Hint</strong>: The KMeans object's
<code>.score()</code> method might be useful here, but note that in
sklearn, scores tend to be defined so that larger is better. Try
applying it to a small, toy dataset, or use an internet search to help
your understanding.</li>
<li>Perform the above two steps for a number of different cluster
counts. You can then see how the average distance decreases with an
increasing number of clusters. However, each additional cluster provides
a smaller net benefit. Use this fact to select a final number of
clusters in which to group the data. <strong>Warning</strong>: because
of the large size of the dataset, it can take a long time for the
algorithm to resolve. The more clusters to fit, the longer the algorithm
will take. You should test for cluster counts through at least 10
clusters to get the full picture, but you shouldn't need to test for a
number of clusters above about 30.</li>
<li>Once you've selected a final number of clusters to use, re-fit a
KMeans instance to perform the clustering operation. Make sure that you
also obtain the cluster assignments for the general demographics data,
since you'll be using them in the final Step 3.3.</li>
</ul>
</section>
<div class="cell code" data-execution_count="63">
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Over a number of different cluster counts...</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_kmeans(data, min_v, max_v, step):</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> []</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>    kmeans_models <span class="op">=</span> []</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, n_clusters <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">range</span>(min_v, max_v<span class="op">+</span><span class="dv">1</span>, step)):</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> ....&#39;</span>)</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># run k-means clustering on the data and...</span></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>        kmeans_models.append(KMeans(n_clusters<span class="op">=</span>n_clusters))</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>        before <span class="op">=</span> time()</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>        kmeans_models[i].fit(data_after_pca)</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>        time_taken <span class="op">=</span> time() <span class="op">-</span> before</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>        mins <span class="op">=</span> <span class="bu">int</span>(time_taken<span class="op">//</span><span class="dv">60</span>)</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>        secs <span class="op">=</span> <span class="bu">int</span>(time_taken<span class="op">%</span><span class="dv">60</span>)</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the average within-cluster distances.</span></span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>        scores.append(<span class="op">-</span>kmeans_models[i].score(data))</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Time taken: </span><span class="sc">{</span>mins<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>secs<span class="sc">}</span><span class="ss">&#39;</span>) </span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Running </span><span class="sc">{</span>n_clusters<span class="sc">}</span><span class="ss"> clusters gives score of </span><span class="sc">{</span>scores[i]<span class="sc">}</span><span class="ch">\n</span><span class="ss">&#39;</span>)</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Returning models &amp; scores</span></span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kmeans_models, scores</span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>global_before <span class="op">=</span> time()</span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>kmeans_models, scores <span class="op">=</span> do_kmeans(data_after_pca, <span class="dv">8</span>, <span class="dv">28</span>, <span class="dv">4</span>)</span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a>global_time_taken <span class="op">=</span> time() <span class="op">-</span> global_before</span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a>mins <span class="op">=</span> <span class="bu">int</span>(global_time_taken<span class="op">//</span><span class="dv">60</span>)</span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a>secs <span class="op">=</span> <span class="bu">int</span>(global_time_taken<span class="op">%</span><span class="dv">60</span>)</span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;The whole process took </span><span class="sc">{</span>mins<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>secs<span class="sc">}</span><span class="ss">.&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>1 ....
Time taken: 2:35
Running 8 clusters gives score of 68162819.50570539

2 ....
Time taken: 4:2
Running 12 clusters gives score of 65515497.711156145

3 ....
Time taken: 7:53
Running 16 clusters gives score of 63485604.54956634

4 ....
Time taken: 10:45
Running 20 clusters gives score of 62135180.90954036

5 ....
Time taken: 12:3
Running 24 clusters gives score of 61032147.553655654

6 ....
Time taken: 13:26
Running 28 clusters gives score of 60026319.02351163

The whole process took 50:50.
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="64">
<div class="sourceCode" id="cb76"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigate the change in within-cluster distance across number of clusters.</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="co"># HINT: Use matplotlib&#39;s plot function to visualize this relationship.</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_kmeans(clusters, scores):</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(clusters, scores, marker<span class="op">=</span><span class="st">&#39;.&#39;</span>, markersize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Num of clusters&#39;</span>)</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Distance from center&#39;</span>)</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;Average distance per number of clusters&#39;</span>)</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>plot_kmeans(<span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">8</span>,<span class="dv">29</span>,<span class="dv">4</span>)), scores)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/1e904e32412677fcb10fa8f05c36281c214d92c9.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="65">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-fit the k-means model with the selected number of clusters and obtain</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="co"># cluster predictions for the general population demographics data.</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>kmeans_model <span class="op">=</span> kmeans_models[<span class="dv">2</span>] <span class="co"># Choosing 16 clusters which is the third model</span></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans_model.predict(data_after_pca)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="66">
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s get back to our pandas dataframe</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>data_with_labels <span class="op">=</span> azdias_clean.copy()</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>data_with_labels[<span class="st">&#39;CLUSTER&#39;</span>] <span class="op">=</span> <span class="bu">list</span>(labels)</span></code></pre></div>
</div>
<section id="discussion-31-apply-clustering-to-general-population"
class="cell markdown">
<h3>Discussion 3.1: Apply Clustering to General Population</h3>
<p>(Double-click this cell and replace this text with your own text,
reporting your findings and decisions regarding clustering. Into how
many clusters have you decided to segment the population?)</p>
<p><strong>ANSWER:</strong> Trying several options between 10 and 30
clusters it seems that choosing 16 clusters is a fine option by the
elbow method.</p>
</section>
<section id="step-32-apply-all-steps-to-the-customer-data"
class="cell markdown">
<h3>Step 3.2: Apply All Steps to the Customer Data</h3>
<p>Now that you have clusters and cluster centers for the general
population, it's time to see how the customer data maps on to those
clusters. Take care to not confuse this for re-fitting all of the models
to the customer data. Instead, you're going to use the fits from the
general population to clean, transform, and cluster the customer data.
In the last step of the project, you will interpret how the general
population fits apply to the customer data.</p>
<ul>
<li>Don't forget when loading in the customers data, that it is
semicolon (<code>;</code>) delimited.</li>
<li>Apply the same feature wrangling, selection, and engineering steps
to the customer demographics using the <code>clean_data()</code>
function you created earlier. (You can assume that the customer
demographics data has similar meaning behind missing data patterns as
the general demographics data.)</li>
<li>Use the sklearn objects from the general demographics data, and
apply their transformations to the customers data. That is, you should
not be using a <code>.fit()</code> or <code>.fit_transform()</code>
method to re-fit the old objects, nor should you be creating new sklearn
objects! Carry the data through the feature scaling, PCA, and clustering
steps, obtaining cluster assignments for all of the data in the customer
demographics data.</li>
</ul>
</section>
<div class="cell code" data-execution_count="67">
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load in the customer demographics data.</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>customers <span class="op">=</span> pd.read_csv(<span class="st">&#39;Udacity_CUSTOMERS_Subset.csv&#39;</span>, sep<span class="op">=</span><span class="st">&#39;;&#39;</span>)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>customers.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="67">
<pre><code>(191652, 85)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="68">
<div class="sourceCode" id="cb81"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply preprocessing, feature transformation, and clustering from the general</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="co"># demographics onto the customer data, obtaining cluster predictions for the</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co"># customer demographics data.</span></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>customers_after_clean, customers_original <span class="op">=</span> clean_data(customers, feat_info, outliers,</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>                                                       threshold, bi_non, to_dummies, to_drop, threshold_to_bi)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Converting all missed data to NaNs...
Removing messy columns and rows...
Number of columns now is 79, should be 79
Selecting, re-encoding and engineering...
OST_WEST_KZ 1/1
Before: [&#39;W&#39; &#39;O&#39;]
After: [0 1]
Number of columns now is 123, should be 123
Number of columns now is 124, should be 124
Number of columns now is 125, should be 125
Number of columns now is 123, should be 123
Number of columns now is 123, should be 123
Number of columns now is 124, should be 124
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="69">
<div class="sourceCode" id="cb83"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Investigating missing values in customers data</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>nan_info(customers_after_clean)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>There are 107491 missing values. (0.6122%).
There are 25947 rows with missing values. (18.33%).
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="70">
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying imputing</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>_, imputed_customers <span class="op">=</span> do_impute(customers_after_clean, model<span class="op">=</span>imputer_model)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="71">
<div class="sourceCode" id="cb86"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying feature scaling</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>_, scaled_customers <span class="op">=</span> do_scale(imputed_customers, model<span class="op">=</span>scaler_model)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="72">
<div class="sourceCode" id="cb87"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying PCA</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>_, customers_after_pca <span class="op">=</span> do_pca(scaled_customers, model<span class="op">=</span>pca_model)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>customers_after_pca.shape</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Time taken: 0:0
</code></pre>
</div>
<div class="output execute_result" data-execution_count="72">
<pre><code>(141590, 68)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="73">
<div class="sourceCode" id="cb90"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Applying clustering</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>customers_labels <span class="op">=</span> kmeans_model.predict(customers_after_pca)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>customers_with_labels <span class="op">=</span> customers_original.copy()</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>customers_with_labels[<span class="st">&#39;CLUSTER&#39;</span>] <span class="op">=</span> <span class="bu">list</span>(customers_labels)</span></code></pre></div>
</div>
<section id="step-33-compare-customer-data-to-demographics-data"
class="cell markdown">
<h3>Step 3.3: Compare Customer Data to Demographics Data</h3>
<p>At this point, you have clustered data based on demographics of the
general population of Germany, and seen how the customer data for a
mail-order sales company maps onto those demographic clusters. In this
final substep, you will compare the two cluster distributions to see
where the strongest customer base for the company is.</p>
<p>Consider the proportion of persons in each cluster for the general
population, and the proportions for the customers. If we think the
company's customer base to be universal, then the cluster assignment
proportions should be fairly similar between the two. If there are only
particular segments of the population that are interested in the
company's products, then we should see a mismatch from one to the other.
If there is a higher proportion of persons in a cluster for the customer
data compared to the general population (e.g. 5% of persons are assigned
to a cluster for the general population, but 15% of the customer data is
closest to that cluster's centroid) then that suggests the people in
that cluster to be a target audience for the company. On the other hand,
the proportion of the data in a cluster being larger in the general
population than the customer data (e.g. only 2% of customers closest to
a population centroid that captures 6% of the data) suggests that group
of persons to be outside of the target demographics.</p>
<p>Take a look at the following points in this step:</p>
<ul>
<li>Compute the proportion of data points in each cluster for the
general population and the customer data. Visualizations will be useful
here: both for the individual dataset proportions, but also to visualize
the ratios in cluster representation between groups. Seaborn's <a
href="https://seaborn.pydata.org/generated/seaborn.countplot.html"><code>countplot()</code></a>
or <a
href="https://seaborn.pydata.org/generated/seaborn.barplot.html"><code>barplot()</code></a>
function could be handy.
<ul>
<li>Recall the analysis you performed in step 1.1.3 of the project,
where you separated out certain data points from the dataset if they had
more than a specified threshold of missing values. If you found that
this group was qualitatively different from the main bulk of the data,
you should treat this as an additional data cluster in this analysis.
Make sure that you account for the number of data points in this subset,
for both the general population and customer datasets, when making your
computations!</li>
</ul></li>
<li>Which cluster or clusters are overrepresented in the customer
dataset compared to the general population? Select at least one such
cluster and infer what kind of people might be represented by that
cluster. Use the principal component interpretations from step 2.3 or
look at additional components to help you make this inference.
Alternatively, you can use the <code>.inverse_transform()</code> method
of the PCA and StandardScaler objects to transform centroids back to the
original data space and interpret the retrieved values directly.</li>
<li>Perform a similar investigation for the underrepresented clusters.
Which cluster or clusters are underrepresented in the customer dataset
compared to the general population, and what kinds of people are
typified by these clusters?</li>
</ul>
</section>
<div class="cell code" data-execution_count="87">
<div class="sourceCode" id="cb91"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the proportion of data in each cluster for the customer data to the</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="co"># proportion of data in each cluster for the general population.</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_clusters(df1, df2):</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sns.countplot(data=df1, x=&#39;CLUSTER&#39;)</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>    df1[<span class="st">&#39;CLUSTER&#39;</span>].hist(density<span class="op">=</span><span class="dv">1</span>, bins<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">16</span>)))</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Proportion of Cluster&#39;</span>)</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;Demographics Data&#39;</span>)</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sns.countplot(data=df2, x=&#39;CLUSTER&#39;)</span></span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>    df2[<span class="st">&#39;CLUSTER&#39;</span>].hist(density<span class="op">=</span><span class="dv">1</span>, bins<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">16</span>)))</span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Cluster&#39;</span>)</span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Proportion of Cluster&#39;</span>)</span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;Customers Data&#39;</span>)</span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb91-19"><a href="#cb91-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb91-20"><a href="#cb91-20" aria-hidden="true" tabindex="-1"></a>show_clusters(data_with_labels, customers_with_labels)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/841384ea1118035f9a09d893f3b7ed8565a04c2e.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="76">
<div class="sourceCode" id="cb92"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What kinds of people are part of a cluster that is overrepresented in the</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="co"># customer data compared to the general population?</span></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_cluster(df, cluster, chosen_features, plot_nr, plot_nc):</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>    THIS_CLUSTER <span class="op">=</span> df[df[<span class="st">&#39;CLUSTER&#39;</span>] <span class="op">==</span> cluster] </span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>    plt.subplots(plot_nr, plot_nc)</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(chosen_features):</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>        plt.subplot(plot_nr, plot_nc, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>        sns.countplot(data<span class="op">=</span>THIS_CLUSTER, x<span class="op">=</span>col)</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>    plt.show</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>chosen_features <span class="op">=</span> [<span class="st">&#39;ALTERSKATEGORIE_GROB&#39;</span>, <span class="st">&#39;ANREDE_KZ&#39;</span>, <span class="st">&#39;LP_LEBENSPHASE_GROB&#39;</span>]</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>show_cluster(data_with_labels, <span class="dv">8</span>, chosen_features, <span class="dv">1</span>, <span class="dv">3</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/24b54faa7dc141646d14132bdcb5e5cdb91dcdf2.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="89">
<div class="sourceCode" id="cb93"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What kinds of people are part of a cluster that is underrepresented in the</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="co"># customer data compared to the general population?</span></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>show_cluster(data_with_labels, <span class="dv">15</span>, chosen_features, <span class="dv">1</span>, <span class="dv">3</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_49444c629f6a44a4acf778a40a7d78e5/0d2bf8ec943fa3f6bbd2eb7690e05083778ffe6d.png" /></p>
</div>
</div>
<section id="discussion-33-compare-customer-data-to-demographics-data"
class="cell markdown">
<h3>Discussion 3.3: Compare Customer Data to Demographics Data</h3>
<p>(Double-click this cell and replace this text with your own text,
reporting findings and conclusions from the clustering analysis. Can we
describe segments of the population that are relatively popular with the
mail-order company, or relatively unpopular with the company?)</p>
<p><strong>ANSWER</strong>: In the overrepresented cluster we can find
the most majority are males of high ages with high incomes. On the other
side, taking a look at the underrepresented cluster, we can see the
quite opposite, majority of females with young ages and less
incomes.</p>
</section>
<div class="cell markdown">
<blockquote>
<p>Congratulations on making it this far in the project! Before you
finish, make sure to check through the entire notebook from top to
bottom to make sure that your analysis follows a logical flow and all of
your findings are documented in <strong>Discussion</strong> cells. Once
you've checked over all of your work, you should export the notebook as
an HTML document to submit for evaluation. You can do this from the
menu, navigating to <strong>File -&gt; Download as -&gt; HTML
(.html)</strong>. You will submit both that document and this notebook
for your project submission.</p>
</blockquote>
</div>
<div class="cell code">
<div class="sourceCode" id="cb94"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
